# Статус проекта:
## Завершен

# Описание проекта
Из «Бета-Банка» стали уходить клиенты. Каждый месяц. Немного, но заметно. Банковские маркетологи посчитали: сохранять текущих клиентов дешевле, чем привлекать новых.
Нужно спрогнозировать, уйдёт клиент из банка в ближайшее время или нет. Вам предоставлены исторические данные о поведении клиентов и расторжении договоров с банком. 

# Цель исследования
Постройте модель с предельно большим значением F1-меры. Чтобы сдать проект успешно, нужно довести метрику до 0.59. Проверьте F1-меру на тестовой выборке самостоятельно.
Дополнительно измеряйте AUC-ROC, сравнивайте её значение с F1-мерой.

# Вывод
С опорой на полученные результаты можно сказать, что модели обученные методом логистической регрессии на всем протяжении исследования показывали самые низкие значения значения F1-меры и самые маленькие площади под ROC-кривой, что говорит о невысокой точности предсказания данного типа моделей при решении конкретной задачи, как на несбалансированных, так и на сбалансированных данных. Модели обученные методом решающего дерева показали промежуточные результаты, как на сбалансированных, так и на несбалансированных данных. Наиболее эффективными проявили себя модели обученные методом случайного леса. Модель обученная с изменением порога (значения класса) на валидационной выборке показала самое высокое значение F1-меры, равное 0,64 и самую большую плозадь под ROC-кривой, равную 0,86.

В результате исследования был выявлен комбинированный способ борьбы с дисбалансом классов основаный на увеличении выборки с одновременным изменением вероятности значения класса, модель обученная методом случайного леса на тестовых данных показала следующие результаты:

- F-1 мера: 0.6047032474804032
- Полнота: 0.6633906633906634
- Точность: 0.5555555555555556
- Площадь под ROC-кривой: 0.8403773573265099
Что удовлетворяет условиям исследования (значение F1-меры > 0,59).

Таким образом для решения задач классификации при условии дисбаланса классов рекомендуется обучение модели случайного леса с увеличением выборки и одновременным изменением вероятности значения класса с шагом 0.02.

# Стек
- pandas
- numpy
- matplotlib
- seaborn
- sklearn
